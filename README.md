# ğŸ§Š Instalily Case Study â€“ Chat Agent for PartSelect

## ğŸ§  Overview

This project implements a **agentic chat system** to support users browsing **Refrigerator** and **Dishwasher** parts on [PartSelect.com](https://www.partselect.com). Initially the goal was to implement a **corrective agentic RAG system**, however this was infeasible with my current skills due to permission rules and bot detection on *PartSelect.com*. The repo leverages:

- **LangChain** + **DeepSeek** for agentic reasoning
- **Playwright** for real-time search and product data scraping
- **ChromaDB** for optional document-based retrieval
- **React** for a responsive chat-based frontend inspired by PartSelect branding

The goal is to build an extensible, task-aware assistant that provides product compatibility, pricing, reviews, installation tips, and troubleshooting help.

---

## ğŸš€ Installation Instructions

### ğŸ§ª Local Installation (only Windows 11 option)

#### ğŸ”§ Python Backend

1. Create the Conda environment and activate:
   ```bash
   conda env create -f environment.yml
   conda activate instalily
   ```

2. Start the backend:
   ```bash
   cd backend
   python main.py
   ```

> ğŸ“ **Note**: Make sure your `.env` file exists in the root directory with `DEEPSEEK_API_KEY` and `OPENAI_API_KEY` configured.

> ğŸ§  If the Chroma vector DB (`backend/db` or `backend/chroma`) was generated with an older LangChain version, **delete the directory** before running to avoid metadata errors.

#### ğŸŒ React Frontend

1. Start the React interface:
   ```bash
   cd case-study-main
   npm install
   npm start
   ```

> ğŸ“ This will serve the frontend at `http://localhost:3000` and connect to the Flask backend on `http://localhost:8000`.

---

### ğŸ³ Docker Installation (Linux - xvfb for headful)

> âœ… Recommended if you want reproducibility or avoid dependency issues.

#### 1. Build and start both frontend and backend

```bash
docker compose up --build
```

This will:

- Start the Flask backend on `http://localhost:8000`
- Serve the React frontend on `http://localhost:3000`

#### 2. Important Notes

- ğŸ“¦ **Chroma vector DB must be rebuilt in Docker** if any metadata errors occur.
  - Delete the old DB folder (e.g., `backend/db` or `backend/chroma`) on your host before first compose run:
    ```bash
    rm -rf backend/db
    ```

- ğŸ” Ensure your `.env` file is included in the build context and contains valid API keys for both DeepSeek and OpenAI:
    ```
    OPENAI_API_KEY=sk-...
    DEEPSEEK_API_KEY=sk-...
    ```

- ğŸ§ª You can verify the backend is running by visiting:
    - `http://localhost:8000/` (backend)
    - `http://localhost:3000/` (frontend)

### ğŸ—‚ï¸ Project Structure

```instalily-case-study/
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ environment.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ open_ai_test.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ working_tree_display.py
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ all_product_links.json
â”‚   â”œâ”€â”€ deep_seek_test.py
â”‚   â”œâ”€â”€ generate_dummy_docs.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ chroma/chroma.sqlite3
â”‚   â”œâ”€â”€ data/refrigerator-manuals/
â”‚   â”‚   â”œâ”€â”€ ps11752778.txt
â”‚   â”‚   â”œâ”€â”€ troubleshooting-guide.txt
â”‚   â”‚   â””â”€â”€ wdt780saem1.txt
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ scraper.py
â”‚   â”‚   â”œâ”€â”€ scraperapi_test.py
â”‚   â”‚   â””â”€â”€ scraper_test.py
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ agent_test.py
â”‚       â”œâ”€â”€ asyncsearch.py
â”‚       â”œâ”€â”€ search.py
â”‚       â””â”€â”€ search_test.py
â”œâ”€â”€ case-study-main/
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ manifest.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.css
â”‚       â”œâ”€â”€ App.js
â”‚       â”œâ”€â”€ index.js
â”‚       â”œâ”€â”€ reportWebVitals.js
â”‚       â”œâ”€â”€ setupTests.js
â”‚       â”œâ”€â”€ api/api.js
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ ChatWindow.css
â”‚           â””â”€â”€ ChatWindow.js
```

### âš ï¸ RAG Limitations & Countermeasures
Scraping product details in bulk proved unreliable due to aggressive anti-bot defenses.

#### Attempted Workarounds
âœ… Rotating proxies (BrightData, ScraperAPI)

âœ… Header spoofing & user-agent substitution

âœ… Playwright stealth mode & randomized delays

âŒ Still blocked when scraping many product pages or running fully headless

### Final Approach
I use on-demand search agents via Playwright to dynamically extract structured product information only when needed, drastically reducing suspicion while preserving functionality. 

